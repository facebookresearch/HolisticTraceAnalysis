{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a4e2e8",
   "metadata": {},
   "source": [
    "__<font color='red'>\n",
    "Note: This feature is currently under development so it will not be fully functional yet. \n",
    "Also, the APIs here are experimental and subject to change.\n",
    "</font>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f114ee",
   "metadata": {},
   "source": [
    "## Setup and loading traces\n",
    "To run this demo notebook on your laptop\n",
    "1. Clone the repo `git clone https://github.com/facebookresearch/HolisticTraceAnalysis.git`\n",
    "1. [Optional and recommended] Setup a conda environment. See README for details.\n",
    "1. Set the `trace_dir` parameter in the next cell to the location of `tests/data/critical_path/simple_add` folder in your local `HolisticTraceAnalysis` installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e32f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProfilerStep not found in the trace. The analysis result may not be accurate.\n"
     ]
    }
   ],
   "source": [
    "from hta.trace_analysis import TraceAnalysis\n",
    "\n",
    "trace_dir = \"/Users/bcoutinho/Work/hta/HolisticTraceAnalysis2/tests/data/critical_path/simple_add/\"\n",
    "\n",
    "analyzer = TraceAnalysis(trace_dir=trace_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2d07a-b4d3-4e7b-87d6-229b32773617",
   "metadata": {},
   "source": [
    "# Critical Path Analysis\n",
    "\n",
    "Critical path analysis is a commonly applied technique in HPC and AI/ML optimization. It can be leveraged in two ways:\n",
    "1. **Efficiency opportunities** Operations/kernels on critical path should be the target of performance analysis and optimizations. They can provide the “best bang for buck” for performance improvements.This is not limited to just CPU/GPU kernels. Delays in launching or executing CUDA kernels can constitute a significant portion of the critical path as well. This could be optimized by operator fusion and CUDA graphs for example.\n",
    "2. **Simulating improvements / gains:** After identifying critical path we can estimate improvements to the execution time without actually running anything. This helps us estimate the possible gains from various performance optimization.\n",
    "\n",
    "## Approach\n",
    "In a nutshell, computing the critical path involves 1) constructing a weighted DAG connecting all the operations, 2) finding the longest path in this DAG. The challenging part is constructing the DAG here. \n",
    "\n",
    "**Nodes**: The Nodes in the critical path graph represent points in time. Each operator/kernel thus has two nodes viz. a begin and an end node. In case of nested operators we also link the nodes in the order they appear in the callstack. An example of stacked operators is shown below-\n",
    "```\n",
    "          |----------------------- Op A ----------------------|\n",
    "                    |--- Op B ---|        |-- Op C--|\n",
    "Critical Path Graph\n",
    "         (OpA.b)--->(ObB.b)----->(OpB.e)->(OpC.b)-->(OpC.e)->(OpA.e)\n",
    "```\n",
    "\n",
    "**Edges** in this DAG can be one of two types\n",
    "1. Timing edges (weight = time): include durations for the operators/kernels as well as delays to launch operators between CPU and GPU.\n",
    "1. Dependency edges (weight = 0): do not have a time component but show a dependency between operations themselves. This includes data dependencies and synchronization between CPU and GPU.\n",
    "\n",
    "## Lightweight Critical Path\n",
    "Our initial implementation of Critical Path analysis does not consider dependency between PyTorch operators, this requires combining the trace with Chakra Execution Traces and processing Tensor information.\n",
    "\n",
    "The key idea here is to simplify the dependency analysis between PyTorch operators\n",
    "- We assume that all CPU operators are dependent serially on the last operator that ran on a CPU thread. This frees us from attempting to correlate with Execution Traces.\n",
    "- The operator dependency part can be added back later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868efbc5-f90b-479d-8c2f-d4a9e26f5ced",
   "metadata": {},
   "source": [
    "## Using this notebook\n",
    "\n",
    "We can demonstrate critical path analysis on most PyTorch traces. However, currently traces are missing\n",
    "information regarding CUDA synchronization. \n",
    "\n",
    "The above is fixed in this [PR](https://github.com/pytorch/pytorch/pull/105187) but not enabled by default. Please follow the documentation in this [PR](https://github.com/pytorch/pytorch/pull/105187) to enable CUDA synchronization events to get best results from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7b1630-9905-437a-92f2-34d3b84d048d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical_path_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mannotation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minstance_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical_path_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform critical path analysis for trace events within a rank.\n",
       "We further reduce the region of interest by selecting\n",
       "a trace annotation and instance id. This will\n",
       "limit the analysis to events within the time range of that annoation.\n",
       "This will include GPU kernels launched by the cpu operators in that\n",
       "time duration.\n",
       "For example, you can use this to limit the analysis to one iteration\n",
       "by passing annotation='ProfilerStep'. See notes for how to pick the iteration.\n",
       "\n",
       "Args:\n",
       "    t (Trace): Input trace data structure.\n",
       "    rank (int): rank to analyze for the critical path.\n",
       "    annotation (str): a trace annotation to limit the analysis to,\n",
       "        for example \"ProfilerStep\" would match all annotations that\n",
       "        match this string (ProfilerStep100, ProfilerStep101 etc)\n",
       "    instance_id: can be either of the following\n",
       "        (int) - specify which instance of the annotation to consider. \n",
       "                Defaults to the first instance.\n",
       "        (Tuple(int, int)) - considers a range of annotation instances start to end,\n",
       "                inclusive of both start and end instance.\n",
       "\n",
       "\n",
       "Returns: Tuple[CPGraph, bool] a pair of CPGraph object and a success or\n",
       "    fail boolean value. True indicates that the critical path analysis\n",
       "    algorithm succeeded.\n",
       "\n",
       "    CPGraph object that can be used to obtain statistics and further\n",
       "    visualize the critical path.\n",
       "\n",
       "    CPGraph is also a subinstance of a networkx.DiGraph.\n",
       "    Run 'CPGraph?' for more info and APIs.\n",
       "\n",
       "Notes:\n",
       "    1. Avoid using the first step / iteration in a trace as it usually\n",
       "       has some missing events.\n",
       "    2. The analysis requires CUDA synchronization events in the GPU trace,\n",
       "       that were added in https://github.com/pytorch/pytorch/pull/105187\n",
       "       Please see the documentation of this PR on how to enable CUDA sync\n",
       "       events in the trace.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Work/hta/HolisticTraceAnalysis2/hta/trace_analysis.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer.critical_path_analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1debaba3-bbac-498b-8f6f-a0b69658e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = \"[param|pytorch.model.alex_net|0|0|0|measure|forward]\"\n",
    "instance_id = 1  # note this is zero based\n",
    "\n",
    "# You can also pass a tuple specifying range of annotation instances\n",
    "# annotation = \"ProfilerStep\"  # will match multiple ProfilerStepXXX annotations\n",
    "# instance_id = (2,3)          # include 3rd to 4th iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8affb1-74f2-4b88-a6eb-85d3a1b67c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hta.configs.config:CUDA Stream Wait event was not matched to a cudaRecordEvent, name = Stream Wait Event\n",
      "WARNING:hta.configs.config:CUDA Stream Wait event was not matched to a cudaRecordEvent, name = Stream Wait Event\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_graph, success = analyzer.critical_path_analysis(\n",
    "    rank = 0, annotation=annotation, instance_id=instance_id)\n",
    "success                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121d9b8-72c8-45a4-972c-7c29c163212b",
   "metadata": {},
   "source": [
    "## Overlay and visualize the Critical Path\n",
    "The `overlay_critical_path_analysis()` function exposes the critical path on the original trace file.\n",
    "There are two modes for the output:\n",
    "1. When `only_show_critical_events=True` (default value) the output trace only contains CPU operators and GPU events on the critical path. One can compare it with the original trace to contrast the critical path identified by the algorithm.\n",
    "1. When `only_show_critical_events=False` in the output trace file search for \"critical\" to highlight events on the critical path.\n",
    "\n",
    "Edges in the critical path graph will be shown using arrows or flow events. Critical edges are marked using the \"critical\" flag in the args property.\n",
    "\n",
    "The category names of flow events begin with \"critical_path_\". They have the following meaning:\n",
    "* `critical_path_dependency`: an inter operator dependency.\n",
    "* `critical_path_operator`: an edge between start and end of a CPU operator or GPU kernel.\n",
    "* `critical_path_kernel_launch_delay`: delay to launch a GPU kernel that is likely to be on the critical path.\n",
    "* `critical_path_kernel_kernel_delay`: delay between running successive GPU kernels.\n",
    "* `critical_path_sync_dependency`: these edges denote synchronization or control dependencies between events such as GPU->CPU, GPU->GPU synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19434b4f-9799-40f3-b6df-ec99fce37246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_critical_path_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcritical_path_graph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical_path_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0monly_show_critical_events\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_all_edges\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Overlay the identified critical path on top of the trace file\n",
       "for visualization.\n",
       "\n",
       "Args:\n",
       "    rank (int): rank to generate the time series for.\n",
       "    critical_path_graph: Critical Path Graph object generated previously\n",
       "    output_dir (str): Output directory to store overlaid trace.\n",
       "    only_show_critical_events (bool): When set the output trace will only\n",
       "        have operators and GPU kernels on the critical path. It will\n",
       "        still retain the user annotations.\n",
       "    show_all_edges (bool): When set this will add edge events for\n",
       "        all types of edges in the critical path graph. This is useful\n",
       "        for debugging the algorithm.\n",
       "\n",
       "Returns: the overlaid trace file path. The generated trace file will\n",
       "have a prefix of \"overlaid_critical_path_\" in its name compared\n",
       "to the original trace file.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Work/hta/HolisticTraceAnalysis2/hta/trace_analysis.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer.overlay_critical_path_analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e20368-2e85-48f1-af48-60d334ec90a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bcoutinho/Work/hta/critical_path/simple_add/overlaid/overlaid_critical_path_benchmark_result_493459_1694039959_trace.json.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure '~/HolisticTraceAnalysis/tests/data/critical_path/simple_add/overlaid' exists or add a different directory\n",
    "# to write your trace too.\n",
    "analyzer.overlay_critical_path_analysis(\n",
    "    0, cp_graph, output_dir='~/HolisticTraceAnalysis/tests/data/critical_path/simple_add/overlaid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982bca5-b1d9-4673-96e2-9a50e14de9e4",
   "metadata": {},
   "source": [
    "## More details on the CPGraph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70c7e2-103c-475a-b030-356fc6f4d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hta.analyzers.critical_path_analysis import CPGraph\n",
    "CPGraph?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
